Gene Annotation
================
Alastair Ludington
2022-12-14

- <a href="#1-introduction" id="toc-1-introduction">1 Introduction</a>
- <a href="#2-de-novo-annotation" id="toc-2-de-novo-annotation">2 De novo
  Annotation</a>
  - <a href="#21-preparation" id="toc-21-preparation">2.1 Preparation</a>
    - <a href="#211-curated-snake-protein-evidence"
      id="toc-211-curated-snake-protein-evidence">2.1.1 Curated snake protein
      evidence</a>
    - <a href="#212-liftoff-of-ncbi-annotations-to-snake-genomes"
      id="toc-212-liftoff-of-ncbi-annotations-to-snake-genomes">2.1.2 Liftoff
      of NCBI annotations to snake genomes</a>
    - <a href="#213-metaeuk-easy-predict"
      id="toc-213-metaeuk-easy-predict">2.1.3 MetaEuk easy-predict</a>
    - <a href="#214-summary" id="toc-214-summary">2.1.4 Summary</a>
  - <a href="#22-funannotate" id="toc-22-funannotate">2.2 Funannotate</a>
    - <a href="#221-funannotate-train" id="toc-221-funannotate-train">2.2.1
      Funannotate Train</a>
    - <a href="#222-funannotate-predict"
      id="toc-222-funannotate-predict">2.2.2 Funannotate Predict</a>
    - <a href="#223-funannotate-update" id="toc-223-funannotate-update">2.2.3
      Funannotate Update</a>
    - <a href="#224-funannotate-annotate"
      id="toc-224-funannotate-annotate">2.2.4 Funannotate Annotate</a>
- <a href="#3-lift-over-annotation" id="toc-3-lift-over-annotation">3
  Lift-over annotation</a>
  - <a href="#31-liftoff" id="toc-31-liftoff">3.1 Liftoff</a>
- <a href="#4-summary" id="toc-4-summary">4 Summary</a>

# 1 Introduction

This repository houses the scripts used for protein coding gene
annotation in *Hydrophis major* and other sea snakes found in the paper.
The methods below were applied (almost identically) to all snakes that I
manually annotated. The actual scripts responsible for annotating each
snake can be found in their respective directories. As such, this
*README* acts as a guide to the annotation process, showing generalised
command calls for reader.

The *de novo* annotated snakes include:

- *Hydrophis major* - New to this study.
- *Hydrophis curtus* - Previously published ([Li et al.,
  2021](https://academic.oup.com/mbe/article/38/11/4867/6329831)) but no
  NCBI annotation available.
- *Hydrophis cyanocinctus* - Previously published ([Li et al.,
  2021](https://academic.oup.com/mbe/article/38/11/4867/6329831)) but no
  NCBI annotation available.

Snakes that did not have sufficient data to be annotated *de novo*, but
were annotated using lift-over software include:

- *Hydrophis elegans* - New to this study.
- *Hydrophis ornatus* - New to this study
- *Hydrophis curtus (AG)* - New to this study

The methods for each of the annotation approaches are detailed below

# 2 De novo Annotation

The *de novo* annotation process involved three distinct approaches that
were integrated to form a final annotation.

1.  Homology-based annotation methods
2.  *De novo* annotation methods
3.  Transcriptome data

Nearly all of the annotation process was managed by the software
[Funannotate (v1.8.11)](https://github.com/nextgenusfs/funannotate).
This tool essentially provides a series of wrapper scripts that automate
the use of many standard gene-annotation tools/methods that users
typically want to run.

## 2.1 Preparation

Prior to running the `Funannotate` pipeline, a few additional input
files were generated. These inputs are used by `Funannotate` in the
`predict` stage of the pipeline. Below, I outline what these files are
and how they were generated.

### 2.1.1 Curated snake protein evidence

Protein sequences from a range of NCBI-annotated snakes ( [Notechis
scutatus](https://www.ncbi.nlm.nih.gov/genome/?term=Notechis%20scutatus),
[Pseudonaja
textilis](https://www.ncbi.nlm.nih.gov/genome/?term=pseudonaja+textilis),
[Naja
naja](https://www.ncbi.nlm.nih.gov/data-hub/genome/GCA_009733165.1/),
[Protobothrops
mucrosquamatus](https://www.ncbi.nlm.nih.gov/genome/?term=Protobothrops+mucrosquamatus)
and [Thamnophis
elegans](https://www.ncbi.nlm.nih.gov/genome/?term=thamnophis+elegans) )
were concatenated into a single FASTA file. The software [MMseqs2
(v13.45111)](https://github.com/soedinglab/MMseqs2) was then used to
generate a non-redundant set of representative sequences. This was
achieved using the `easy-cluster` argument, which uses a cascade
clustering algorithm.

The script used to generate the representative protein sequences is
`00-mmseqs2-cluster-snake-proteins.sh` which is found in the
`scripts/hydrophis_major` directory. These same curated proteins were
used for the other snakes that we annotated.

``` bash
# Reduce the protein set down to a 'representative', non-redundant set
mmseqs easy-cluster \
    "${PROT}/snake-proteins.faa" \
    "${PROT}/snake-proteins-clustered" \
    "${PROT}/mmtemp" \
    --min-seq-id 0.9 \
    -c 0.9 \
    --cluster-reassign \
    --threads "${PBS_NCPUS}"
```

The representative sequences generated by this step are used as protein
evidence in the actual annotation pipeline.

### 2.1.2 Liftoff of NCBI annotations to snake genomes

As an additional line of evidence, [Liftoff
(v1.6.3)](https://github.com/agshumate/Liftoff) was used to lift
annotations from the NCBI snakes listed above, along with [Anolis
Carolinensis](https://www.ncbi.nlm.nih.gov/genome/?term=Anolis+carolinensis),
to the genomes of interest. These annotations were then processed to be
[EVM (v1.1.1)](http://evidencemodeler.github.io/) compatible using the
script `liftoff-to-evm.R`.

``` bash
# NCBI annotated samples
SMP='anolis_carolinensis naja_naja notechis_scutatus protobothrops_mucrosquamatus pseudonaja_textilis thamnophis_elegans'

# Iterate over each NCBI annotation and lift it over to our 'refernece' of interest
for SAMPLE in ${SMP}; do
    mkdir -p "${OUT}/liftoff-${SAMPLE}"

    if [[ ! -f "${OUT}/liftoff-${SAMPLE}/${SAMPLE}-to-reference.gff3" ]]; then
       printf '[LiftOff] %s\n' "${SAMPLE} to reference"

       # Lift annotations over
       liftoff \
           "${ASM}" \
           "${REF}/${SAMPLE}.fna" \
           -g "${GFF}/${SAMPLE}.gff3" \
           -o "${OUT}/liftoff-${SAMPLE}/${SAMPLE}-to-reference.gff3" \
           -u "${OUT}/liftoff-${SAMPLE}/${SAMPLE}-to-reference.unmapped.txt" \
           -exclude_partial \
           -flank 0.1 \
           -dir "${OUT}/${SAMPLE}-intermediates" \
           -p 50 &> "${OUT}/liftoff-${SAMPLE}/${SAMPLE}.log"

        # Extract CDS as nuc/pep
        gffread "${OUT}/liftoff-${SAMPLE}/${SAMPLE}-to-reference.gff3" \
            -g "${ASM}" \
            -y "${OUT}/liftoff-${SAMPLE}/${SAMPLE}-to-reference.faa" \
            -x "${OUT}/liftoff-${SAMPLE}/${SAMPLE}-to-reference.fna"
   fi
done
```

These output files, which are `EVM` compatible *GFF3* files, were then
used as `OTHER` evidence to `EVM` during the formation of the
non-redundant gene set.

### 2.1.3 MetaEuk easy-predict

The final external gene evidence we generated was homlogy-based gene
predictions using [MetaEuk
(v6.a5d39d9)](https://github.com/soedinglab/metaeuk#easy-predict-workflow).
The curated snake proteins generated by `MMseqs2`, along with the
[UniProt (SwissProt)](https://www.uniprot.org/) protein database were
provided as input to `MetaEuk easy-predict`. `Easy-predict` annotations
were generated for each of the snakes of interest. The `easy-predict`
module incorporates the following `MetaEuk` modules into a single step:
*predictexons*, *reduceredundancy* and *unitesetstofasta*.

``` bash
# Predict gene models based on protein homology
metaeuk easy-predict \
    reference.fa \
    proteins.fa \
    "${OUT}/metaeuk-predictions" \
    "${OUT}" \
    --min-seq-id 0.7 \
    --max-intron 150000 \
    --threads 50 \
    --headers-split-mode 1 \
    --remove-tmp-files
```

*GFF3* outputs from this step were then made `EVM` compatible by using
the script `metaeuk-to-evm.R`.

### 2.1.4 Summary

To summarise the preparation steps, there are three main outputs that
have been generated, where each output type may have multiple files
associated with it.

1.  A non-redundant set of snake protein sequences generated by
    `MMseqs2`
2.  `EVM` compatible *GFF3* files generated by lifting NCBI gene
    annotations to the species of interest using `Liftoff`
3.  `EVM` compatible *GFF3* files generated by predicting gene structure
    from protein homology using `MetaEuk` relative to the species of
    interest

Each of these outputs are used in the actual annotation pipeline
outlined below.

## 2.2 Funannotate

[Funannotate](https://github.com/nextgenusfs/funannotate) is a gene
prediction software package. It acts as a wrapper around a bunch of
common gene prediction tools, linking common annotation processes
together in a single pipeline. The beauty of `Funannotate` is that it
automates a lot of the annoying, manual processes that users normally
have to deal with.

There are four main stages to `Funannotate`. These are:

1.  Train
2.  Predict
3.  Update
4.  Annotate

I’ll go through each of them below.

### 2.2.1 Funannotate Train

The `train` module is a wrapper around [Genome Guided Trinity
(v2.8.5)](https://github.com/trinityrnaseq/trinityrnaseq/wiki/Genome-Guided-Trinity-Transcriptome-Assembly)
and [PASA (v2.4.1)](https://github.com/PASApipeline/PASApipeline/wiki).
This stage is responsible for generating the inputs for the `predict`
module, but doesn’t actually run any ‘training’ (the name is a bit
confusing in that regard).

The training module was run twice: once on the soft-masked *H. major*
genome, and once on the un-masked genome. This was done to generate as
much information as possible for the gene prediction step.

This stage taks the RNA-seq as input, along with a maximum intron length
value (used to simplify RNA-seq spliced alignment).

``` bash
# Generate a range of useful data from the RNA-seq
singularity exec "${CONTAINER}/funannotate-v1.8.11.sif" funannotate train \
    --input "${ASM}" \
    --out "${OUT}" \
    --left "${RNA}/left.fastq.gz" \
    --right "${RNA}/right.fastq.gz" \
    --no_trimmomatic \
    --max_intronlen 150000 \
    --species "Hydrophis major" \
    --cpus "${PBS_NCPUS}"
```

### 2.2.2 Funannotate Predict

The `predict` module does most of the work in the `Funannotate`
pipeline. It is responsible for predicting gene models using a range of
tools and approaches. At this stage, the pipeline does the following:

- Parse the outputs generated by `train` and train the *de novo*
  prediction tools:
  - [AUGUSTUS (v3.3.2)](https://github.com/Gaius-Augustus/Augustus)
  - [SNAP (v2006-07-28)](https://github.com/KorfLab/SNAP)
  - [GeneMark (v4.69)](http://exon.gatech.edu/GeneMark/)
  - [GlimmerHMM (v3.0.4)](https://ccb.jhu.edu/software/glimmerhmm/)
- Run the trained *de novo* gene prediction tools.
- Align protein sequences to the reference genome using [Exonerate
  (v2.4.0)](https://www.ebi.ac.uk/about/vertebrate-genomics/software/exonerate)
  (`MMseqs2` curated set).
- Generate a non-redundant set of gene predictions by integrating all
  sources of evidence gene-prediction evidence.
  - *De novo* gene model predictions (`AUGUSTUS`, `SNAP`, `GeneMark`,
    `GlimmerHMM`)
  - Homology gene models (`Exonerate` protein alignments)
  - Transcript gene models (`PASA` gene models)
  - Other forms of evidence (`MetaEuk` and `Liftoff`)

The `predict` module was first run on the **masked genome**. The
non-redundant set of gene predictions produced for the masked genome
were then passed as inputs to the un-masked `predict` run as a form of
`OTHER` evidence.

``` bash
# Predict gene models using a range of tools
singularity exec "${CONTAINER}/funannotate-v1.8.11.sif" funannotate predict \
    --input "${ASM}" \
    --out "${OUT}" \
    --species "Hydrophis major_nm" \
    --weights genemark:1 \
    --other_gff "metaeuk-evm_valid.gff3:3" "anolis_carolinensis-to-hydrophis_major-evm_valid.gff3:3" "naja_naja-to-hydrophis_major-evm_valid.gff3:3" "notechis_scutatus-to-hydrophis_major-evm_valid.gff3:3" "protobothrops_mucrosquamatus-to-hydrophis_major-evm_valid.gff3:3" "pseudonaja_textilis-to-hydrophis_major-evm_valid.gff3:3" "thamnophis_elegans-to-hydrophis_major-evm_valid.gff3:3" "${EVM}:3" \
    --database '/home/566/al4518/al/database/funannotate_db' \
    --busco_db 'tetrapoda' \
    --organism 'other' \
    --max_intronlen 150000 \
    --genemark_gtf "${DIR}/genemark-es-out/genemark.gtf" \
    --protein_evidence "${PRO}/snake-proteins-clustered_rep_seq.fasta" \
    --tmpdir "${DIR}" \
    --cpus "${PBS_NCPUS}" \
    --force
```

### 2.2.3 Funannotate Update

This module updates the predicted gene modules using the RNA-seq data
and `PASA` models. Specifically, the pipeline involves comparing
predicted gene models to the `Trinity` transcripts assembled into gene
loci by `PASA`, correcting 5’ and 3’ UTR regions and intron/exon
structure. High confidence gene models are then selected based on their
expression, which is quantified using the software [Kallisto
(v0.46.1)](https://pachterlab.github.io/kallisto/about).

``` bash
# Update command to improve gene model accuracy
singularity exec ${CONTAINER}/funannotate-v1.8.11.sif funannotate update \
    -i '/g/data/xl04/al4518/hydmaj-genome/funannotate/annotation-funannotate-no-mask' \
    --cpus "${PBS_NCPUS}"
```

### 2.2.4 Funannotate Annotate

The next step of the `Funannotate` pipeline is to add functional
annotations to the updated gene models. `Funannotate` is able to
integrate multiple sources of information to form a singular functional
annotation. We ran the following two tools manually and passed their
outputs to `Funannotate annotate`.

The first source of annotation came from mapping the predicted gene
sequences to the [eggNOG v(5.0)](http://eggnog5.embl.de/#/app/home)
database using [eggnog-mapper
(v2.1.9)](https://github.com/eggnogdb/eggnog-mapper).

``` bash
# Map the protein sequences to the EggNOG v5 database
emapper.py \
    --cpu "${PBS_NCPUS}" \
    -i "${PROT}" \
    --itype 'proteins' \
    --pident 80 \
    --query_cover 80 \
    --output 'Hydrophis_major-emapper' \
    --output_dir "${OUT}"
```

[InterPro (v5.57-90.0)](https://github.com/ebi-pf-team/interproscan) was
also used to functionally annotate predicted gene sequences by searching
all default homology databases.

``` bash
# Annotate the updated protein sequences using IPS and its default databases
"${IPS}/interproscan.sh" \
    --cpu "${SLURM_CPUS_PER_TASK}" \
    --output-file-base "${OUT}/Hydrophis_major" \
    --disable-precalc \
    --goterms \
    --input "${PROT}" \
    --iprlookup \
    --pathways
```

The final stage of the `Funannotate` pipeline was then run using the
command below, passing both sources of functional annotation. The
`annotate` step assigns gene names/symbols, *GO Terms* and other
functional domains to each gene, where applicable.

``` bash
# Annotate updated protein coding gene models
singularity exec "${CONTAINER}/funannotate-v1.8.11.sif" funannotate annotate \
    -i '/g/data/xl04/al4518/hydmaj-genome/funannotate/annotation-funannotate-no-mask' \
    --cpus "${PBS_NCPUS}" \
    --eggnog "${EGG}" \
    --iprscan "${IPS}" \
    --busco_db 'tetrapoda' \
    --database '/home/566/al4518/al/database/funannotate_db' \
    --tmpdir "${PWD}" \
    --no-progress
```

# 3 Lift-over annotation

For lift-over methods, the software [Liftoff
(v1.6.3)](https://github.com/agshumate/Liftoff) was used to lift-over
the *H. major* gene annotations to the following snakes:

- *Hydrophis elegans*
- *Hydrophis ornatus*
- *Hydrophis curtus (AG)*

The *H. major* annotations were used as the refernce gene-set as they
had the highest `BUSCO` score of closely related *Hydrophis* snakes.

## 3.1 Liftoff

As stated in the introduction, the software [Liftoff
(v1.6.3)](https://github.com/agshumate/Liftoff) was used to annotate the
three sea snakes listed above. `Liftoff` is a relatively simple tool to
use, simply requiring a target genome that is annotated (*H. major*) and
a subject genome to lift the annotation to. The code used to annotate
the three genomes using `Liftoff` can be found in
`liftoff-to-genomes.sh`. The key code is shown below:

``` bash
liftoff \
    "${QRY_ASM}" \                # Lift annotations to
    "${TGT_ASM}" \                # Lift annotations from
    -g "${TGT_GFF}" \
    -o "${OUT}/${BN}/${BN}.gff3" \
    -u "${OUT}/${BN}/${BN}-unmapped.txt" \
    -exclude_partial \
    -dir "${OUT}/${BN}/intermediates" \
    -p "${SLURM_CPUS_PER_TASK}" \
    -polish
```

# 4 Summary

This document details both the *de novo* and lift-over methods used to
annotate the new and existing sea snakes for this study. The relevant
scripts for each annotation approach can be found in the `scripts`
directory. Most scripts are numbered by the order that they should be
run, and should be intuitive enough to figure out given this document
and their order of execution.
